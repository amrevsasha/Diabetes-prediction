import numpy as np
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.metrics import precision_score, recall_score, roc_auc_score
from sklearn.feature_selection import SelectKBest, f_classif
import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc, confusion_matrix, ConfusionMatrixDisplay



# Load and preprocess the dataset
import pandas as pd

data = pd.read_csv(r'C:\Users\91800\Dropbox\PC\Documents\major pro-diabetes\diabetes (1).csv')
features = data.iloc[:, :-1]
labels = data.iloc[:, -1]
x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)

# Normalize the features
mean = np.mean(x_train, axis=0)
std = np.std(x_train, axis=0)
x_train = (x_train - mean) / std
x_test = (x_test - mean) / std

# Define the deep learning model
model = tf.keras.models.Sequential([
    tf.keras.layers.Dense(64, activation='relu', input_shape=(x_train.shape[1],)),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

# Compile and train the model
optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)
model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])
model.fit(x_train, y_train, epochs=15, batch_size=32, validation_data=(x_test, y_test))

# Make predictions on the test set
y_pred = model.predict(x_test)
y_pred_binary = np.round(y_pred)

# Calculate precision, recall, and area under the ROC curve
precision = precision_score(y_test, y_pred_binary)
recall = recall_score(y_test, y_pred_binary)
roc_auc = roc_auc_score(y_test, y_pred)
loss, accuracy = model.evaluate(x_test, y_test)
# Print the evaluation metrics
print('Test Loss:', loss)
print('Test Accuracy:', accuracy)
print('Precision:', precision)
print('Recall:', recall)
print('Area under ROC Curve:', roc_auc)
# Train an SVM classifier
rf =  tf.keras.models.Sequential([
    tf.keras.layers.Dense(64, activation='relu', input_shape=(x_train.shape[1],)),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')
])
# Split the dataset into train and test sets
X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)

# Compile and train the model
optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)
rf.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])
rf.fit(x_train, y_train, epochs=15, batch_size=32, validation_data=(x_test, y_test))
rf.fit(X_train, y_train)


# Predict probabilities of positive class for test set
y_probs = rf.predict(X_test)[:, 0]

# Calculate false positive rate, true positive rate, and thresholds
fpr, tpr, thresholds = roc_curve(y_test, y_probs)

# Calculate the Area Under the ROC Curve (AUROC)
roc_auc = auc(fpr, tpr)





y_pred_binary = (y_probs >= 0.5).astype(int)

from sklearn.metrics import confusion_matrix

cm = confusion_matrix(y_test, y_pred_binary)


import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix


# Plot the confusion matrix using seaborn
# Plot confusion matrix
plt.figure(figsize=(6, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')
plt.show()
